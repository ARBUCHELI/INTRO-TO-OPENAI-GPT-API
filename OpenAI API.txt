# OPENAI API
------------

* Introduction
--------------
An Application Programming Interface (API) is an excellent way for developers to interact with third-party software easily. Data and functionality can be accessed by sending requests to 
different API endpoints. Using APIs is a great way to expand your project’s scope and capabilities.

The OpenAI API is no different because it is a portal into the world of large language models and brings generative AI into our code. Understanding this API is important when working with 
generative AI in your code and projects.

Generative AI applications like ChatGPT use large language models (LLMs). LLMs, in turn, are built using a technology known as Generative Pre-trained Transformer (and they are named after 
it, hence GPT-4). A main driver of these models is the Neural Network. Based loosely on the human brain’s functionality, neural networks are trained on a large amount of data to reproduce 
certain behaviors.

While powerful and very effective, neural networks operate as a black box because their inner workings are a mystery to even the most highly-trained data scientists. This results in 
unverifiable model output, where the input and outputs are always processed with a certain amount of randomness.

This lesson will examine the OpenAI API and explain how to create more reliable, controlled outputs from LLMs. We will explore the API’s different generative AI tasks and model offerings, 
examine the API request and response objects, and look at effectively creating input prompts to receive the desired text output. We will also look at controlling the output with 
hyperparameters to counteract the model’s non-deterministic or random behavior.

* Instructions
--------------
The GPT simulator on the right lets you input specific prompts and get a corresponding output. To do this, select a preset prompt by clicking the button labeled with the prompt text. 
Then, press the triangle button to the right to submit it. If you wish to remove all output text, click the circular arrow button located next to the triangle button.

Try submitting each prompt multiple times and observe the output.

You’ll see that depending on the input prompt, the output might be less deterministic and differ with each submission. Using the API, you will learn how to gain some control of the output 
based on the given input.

When you’re done, move to the next exercise.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------

* Endpoints
-----------
The OpenAI API can be used for text completion, image generation and modification, audio transcription, and more. Text completion, including code generation, is a popular use case for 
large language models and is what we will focus on in this course.

API endpoints are server locations where data can be sent and received using code or other means. OpenAI’s API has two endpoints that handle text completion: chat/completions and 
completions. Let’s compare these two text completion endpoints.

. chat/completions
------------------

The chat/completions endpoint generates text from a single prompt or defines a multi-prompt chat.

The chat functionality allows us first to set the “behavior” of the chat replies, such as “You are to respond to 8th-grade social studies questions.” Once this is defined, the responses 
will be on an 8th-grade social studies class level, and questions not involving social studies will potentially be rejected.

Using this endpoint, we can also specify a small number of prompt/response examples to help guide future responses. This is known as few-shot prompting and can profoundly affect the 
chat’s behavior.

. completions
-------------
The completions endpoint produces a text completion output using a single input prompt. While this behavior is also available in the chat/completions, the completions endpoint does 
provide more hyperparameters for tuning the model’s behavior which could be useful for some developers.

However, despite offering those extra hyperparameters that aren’t available in chat/completions, the completions endpoint is not as useful overall since it only supports a single prompt 
for completion and uses older LLMs that are less powerful and cost more.

. Other Endpoints
-----------------
While we will be focusing on the chat/completions and completions endpoints in this course, it is good to know about some of the other endpoints accessible with the API:

	. models: List the available models and corresponding data such as owner and permissions
	. images: Create and edit images using a text prompt
	. audio: Generate text from a given audio file
	. moderations: Analyze text to see if it violates OpenAI’s content policy, which is useful when passing a user’s input through to the API

. Instructions
--------------
Click the generative AI categories on the right to reveal the associated endpoint and description.

- Chat and Text Completion Endpoint 
-----------------------------------
'chat/completions'

Generates and completes text from a single prompt or defines a multi-prompt chat.

- Text Completion Endpoint
--------------------------
'completions'
Generates and completes text from a single prompt.

- Available Models Endpoint
---------------------------
'models'
List the available models and corresponding data.

- Image Creation Endpoint
-------------------------
'images'
Create and edit images using a text prompt.

- Audio Transcription Endpoint
------------------------------
'audio'
Generates text from a given audio file

- Content Moderation Endpoint
-----------------------------
'moderations'
Analyzes text to see if it violates OpenAI's content policy.

------------------------------------------------------------------------------------------------------------------------------------------------------------------






























